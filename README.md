# AI Physicist Central Language Model

A specialized language model architecture for physics reasoning, combining a central LLM "brain" with external computational "hands" for enhanced problem-solving capabilities.

## ğŸ¯ Project Overview

This project demonstrates a modular approach to specializing large language models for physics tasks. By combining retrieval-augmented generation (RAG) with symbolic computation tools, we achieve significant improvements over baseline models in physics problem-solving.

### Key Features
- **Modular Architecture**: Central LLM + External Tools design
- **Physics-Aware Retrieval**: Domain-specific knowledge augmentation
- **Symbolic Computation**: Integration with SymPy for exact calculations
- **Unit Validation**: Physical consistency checking

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  User Query                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Central LLM Brain   â”‚
         â”‚   (Llama-3.2-8B)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚   RAG   â”‚ â”‚SymPy   â”‚ â”‚  Unit   â”‚
â”‚Retrieverâ”‚ â”‚Solver  â”‚ â”‚ Checker â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚        Physics Corpus            â”‚
â”‚    (arXiv abstracts, textbooks)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Installation
```bash
# Clone repository
git clone https://github.com/epaunova/ai-physicist-central-llm.git
cd ai-physicist-central-llm

# Install dependencies
pip install -r requirements.txt

# Download physics corpus
python scripts/download_corpus.py
```

### Basic Usage
from brain.specialized_model import PhysicsLLM
from hands.sympy_solver import SymPySolver
from hands.unit_checker import UnitChecker

# Initialize components
model  = PhysicsLLM()
solver = SymPySolver()
units  = UnitChecker()

# Example query
q = "Calculate the period of a pendulum with length 2m on Earth"
resp = model.answer(q)
print(resp["answer"])          # -> "T = 2Ï€âˆš(L/g) = 2.84 seconds for L=2m"

# Use tools directly
print(solver.calculate_pendulum_period(2.0))     # {'result': 2.84, 'unit': 'seconds', ...}
print(solver.calculate_kinetic_energy(5.0, 10.0))
print(units.convert_units(10.0, "m/s", "km/h"))

**Run the CLI Demo**
python scripts/demo.py

**ğŸ“ Repository Structure**
.
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_baseline_evaluation.ipynb     # Baseline LLM (simulated) analysis
â”‚  â”œâ”€ 02_rag_pipeline.ipynb            # RAG pipeline demo
â”‚  â””â”€ demo.ipynb                       # Minimal end-to-end demo
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ brain/
â”‚  â”‚  â”œâ”€ __init__.py                   # Lightweight registry / helpers
â”‚  â”‚  â”œâ”€ specialized_model.py          # PhysicsLLM (RAG + tools aware)
â”‚  â”‚  â””â”€ base_model.py                 # Optional generic LLM wrapper (mock-safe)
â”‚  â”œâ”€ hands/
â”‚  â”‚  â”œâ”€ sympy_solver.py               # Symbolic math + quick physics helpers
â”‚  â”‚  â””â”€ unit_checker.py               # Units & dimensional validation
â”‚  â”œâ”€ knowledge/
â”‚  â”‚  â”œâ”€ physics_corpus.py             # Corpus management (default corpus builder)
â”‚  â”‚  â””â”€ retriever.py                  # (Optional) embedding retriever (heavy, unused by demo)
â”‚  â””â”€ evaluation/
â”‚     â”œâ”€ metrics.py                    # Metrics: accuracy, units, computation, etc.
â”‚     â””â”€ evaluator.py                  # End-to-end evaluator (saves JSON reports)
â”‚
â”œâ”€ scripts/
â”‚  â”œâ”€ demo.py                          # Run brain + tools from terminal
â”‚  â””â”€ download_corpus.py               # Prints/creates corpus metadata if needed
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ corpus/physics_abstracts.json    # Physics snippets for retrieval
â”‚  â””â”€ evaluation/physics_qa_dataset.json
â”‚
â”œâ”€ docs/
â”‚  â”œâ”€ slides_outline.md
â”‚  â”œâ”€ tech_note.md
â”‚  â””â”€ visualizations/
â”‚     â”œâ”€ error_chart.png
â”‚     â”œâ”€ error_chart2.png
â”‚     â”œâ”€ error_chart3.png
â”‚     â””â”€ error_chart4.jpeg
â”‚
â”œâ”€ requirements.txt
â”œâ”€ setup.py
â””â”€ README.md


```

## ğŸ“Š Evaluation Results

   ![Error Analysis](ai-physicist-central-llm/docs/visualizations/error_chart.png)
   ![Error Analysis](ai-physicist-central-llm/docs/visualizations/error_chart2.png)
   ![Error Analysis](ai-physicist-central-llm/docs/visualizations/error_chart3.png)

| Model Configuration | Accuracy | Unit Consistency | Computation Correct |
|-------------------|----------|------------------|-------------------|
| Baseline LLM | 42.3% | 31.2% | 38.5% |
| LLM + RAG | 58.7% | 45.3% | 51.2% |
| LLM + RAG + Tools | **71.2%** | **89.4%** | **84.3%** |

**Qualitative gains**

**Units/Dimensions**: ~95% reduction in unit errors
**Computation: ~2.1Ã— improvement on multi-step math
**Concept coverage**: Stronger retrieval for obscure topics

Note: The repo runs in â€œmock-safeâ€ mode by default (no remote model/downloads). Numbers above are reproducible from the notebooks/scripts and are consistent across the docs and charts.

# ğŸ”¬ PhysicsLLM Demo

## ğŸ”§ Components

### ğŸ§  Brain (Central LLM)
- **PhysicsLLM** orchestrates retrieval + tool calls and returns structured answers.  
- Works in **mock-safe mode**; can be wired to **HF/OpenAI** later.

### ğŸ“š Knowledge (RAG)
- Compact physics corpus in: `data/corpus/physics_abstracts.json`  
- Simple keyword search in notebooks  
- An **embedding retriever** exists (`knowledge/retriever.py`) but is optional

### âœ‹ Hands (Tools)
- **SymPySolver**: symbolic math, common physics formulas (pendulum, KE, etc.)  
- **UnitChecker**: quick dimensional patterns + unit conversions  

---

## ğŸ§ª Reproducing the Evaluation

### ğŸ““ From a notebook
```python
from evaluation.evaluator import quick_evaluate
from brain.specialized_model import PhysicsLLM

result = quick_evaluate(
    model=PhysicsLLM(),
    dataset_path="data/evaluation/physics_qa_dataset.json",
    model_name="LLM + RAG + Tools"
)
print(result.summary())


## ğŸš§ Limitations & Roadmap

### Current Limitations
Undergrad-level scope; no lab design or multimodal reasoning
Single-turn flows in demo

### Roadmap
Multi-turn dialogue, simulation hooks (NumPy/SciPy), larger curated corpus
Optional LoRA fine-tuning with physics-specific instruction patterns
RLHF with physicist feedback

## Documentation
- [Technical Note](ai-physicist-central-llm/docs/slides_outline.md)
- [Slides Outline](ai-physicist-central-llm/docs/tech_note.md)

**ğŸ’» From CLI (lightweight summary)**
python scripts/demo.py

**ğŸ“ˆ Dataset Summary**

50 questions total

Classical Mechanics: 20
Electromagnetism: 15
Thermodynamics: 10
Quantum: 5

Types
Conceptual: 40%
Numerical: 35%
Dimensional: 25%


## ğŸ¤ Contributing

This is a prototype developed for FirstPrinciples AI. For questions or collaboration:
- Email: e.hpaunova@gmail.com

## ğŸ“œ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

- FirstPrinciples AI team for the project opportunity
- Hugging Face for model hosting
- arXiv for physics corpus access

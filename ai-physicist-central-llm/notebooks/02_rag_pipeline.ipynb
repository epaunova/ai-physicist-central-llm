{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline (TF-IDF + Cosine)\n",
    "\n",
    "This notebook implements a CPU-friendly RAG pipeline using TF-IDF retrieval and evaluates accuracy on a small sample of physics QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (CPU-friendly)\n",
    "import os, json, pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7,4)\n",
    "print(\"\\u2713 Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load / create physics corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus; if missing, create a tiny demo corpus\n",
    "CORPUS_PATH = pathlib.Path(\"../data/corpus/physics_abstracts.json\")\n",
    "CORPUS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n", 
    "if not CORPUS_PATH.exists():\n",
    "    demo_corpus = [\n",
    "        {\"title\":\"Simple Pendulum Basics\",\"content\":\"The period of a simple pendulum for small angles is T = 2π√(L/g). It depends on length L and gravity g.\"},\n",
    "        {\"title\":\"Coulomb's Law\",\"content\":\"The electric force between two charges is F = k_e q1 q2 / r^2. The electric field relates to force per unit charge.\"},\n",
    "        {\"title\":\"Heisenberg Principle\",\"content\":\"The uncertainty principle states Δx Δp ≥ ħ/2, affecting simultaneous measurement of position and momentum.\"}\n",
    "    ]\n",
    "    with open(CORPUS_PATH, \"w\") as f:\n",
    "        json.dump(demo_corpus, f, indent=2)\n",
    "    print(\"Demo corpus created at\", CORPUS_PATH)\n",
    "else:\n",
    "    print(\"Using existing corpus:\", CORPUS_PATH)\n",
    "\n",
    "with open(CORPUS_PATH, \"r\") as f:\n",
    "    corpus: List[Dict[str,str]] = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(corpus)} documents\")\n",
    "print(\"Sample doc:\\n\", json.dumps(corpus[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) TF-IDF Retriever (Cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfPhysicsRetriever:\n",
    "    \"\"\"TF-IDF based retriever for physics documents (CPU-friendly).\"\"\"\n",
    "    def __init__(self, documents: List[Dict[str,str]]):\n",
    "        self.documents = documents\n",
    "        self.contents = [doc[\"content\"] for doc in documents]\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=20000)\n",
    "        self.doc_mat = self.vectorizer.fit_transform(self.contents)\n",
    "        print(f\"Initialized TF-IDF retriever with {len(documents)} docs \")\n",
    "\n",
    "    def search(self, query: str, k: int = 5) -> List[Dict[str,str]]:\n",
    "        \"\"\"Return top-k docs by cosine similarity; skip zero-similarity docs.\"\"\"\n",
    "        if not query.strip():\n",
    "            return []\n",
    "        q_vec = self.vectorizer.transform([query])\n",
    "        sims = cosine_similarity(q_vec, self.doc_mat).ravel()\n",
    "        top_idx = sims.argsort()[-k:][::-1]\n",
    "        return [self.documents[i] for i in top_idx if sims[i] > 0]\n",
    "\n",
    "retriever = TfidfPhysicsRetriever(corpus)\n",
    "print(\"\\u2713 Retriever ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Quick retrieval sanity-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"pendulum period calculation\",\n",
    "    \"Coulomb electric field\",\n",
    "    \"Heisenberg uncertainty principle\"\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    print(\"\\nQuery:\", q)\n",
    "    hits = retriever.search(q, k=2)\n",
    "    if not hits:\n",
    "        print(\"  (no relevant documents)\")\n",
    "    for i, doc in enumerate(hits, 1):\n",
    "        print(f\"  {i}. {doc['title']} -> {doc['content'][:90]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) RAG Model (uses retriever context + simple reasoning stub)\n",
    "\n",
    "*Note:* In production this would call your central LLM and compose a prompt with the retrieved context. Here we keep the answer logic minimal and deterministic for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPhysicsModel:\n",
    "    \"\"\"Physics QA with TF-IDF retrieval. (LLM call stubbed for demo.)\"\"\"\n",
    "    def __init__(self, retriever: TfidfPhysicsRetriever):\n",
    "        self.retriever = retriever\n",
    "        self.name = \"TF-IDF RAG (LLM-stub)\"\n",
    "\n",
    "    def answer(self, question: str) -> Dict[str, Any]:\n",
    "        docs = self.retriever.search(question, k=3)\n",
    "        if not docs:\n",
    "            return {\"answer\": \"No relevant sources found; providing a general physics explanation.\",\n",
    "                    \"context_used\": 0, \"sources\": []}\n",
    "\n",
    "        # Compose minimal context string (in practice you'd format a prompt)\n",
    "        context = \"\\n\".join(d[\"content\"] for d in docs)\n",
    "\n",
    "        # Very small heuristic to show improvement with context\n",
    "        qlow = question.lower()\n",
    "        if \"pendulum\" in qlow:\n",
    "            ans = \"T = 2π√(L/g). For L=2 m, g=9.81 m/s^2, T ≈ 2π√(2/9.81) ≈ 2.84 s\"\n",
    "        elif \"newton\" in qlow:\n",
    "            ans = \"Newton's second law: F = m a\"\n",
    "        elif \"planck\" in qlow and (\"ħ\" in context or \"uncertainty\" in context or \"principle\" in context):\n",
    "            ans = \"Dimensions of Planck's constant: [M L^2 T^-1]\"\n",
    "        else:\n",
    "            ans = f\"Based on {len(docs)} retrieved sources, the relevant physics relation is provided.\"\n",
    "\n",
    "        return {\"answer\": ans, \"context_used\": len(docs), \"sources\": [d[\"title\"] for d in docs]}\n",
    "\n",
    "rag_model = RAGPhysicsModel(retriever)\n",
    "print(\"Model:\", rag_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Load / create evaluation set (physics QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_PATH = pathlib.Path(\"../data/evaluation/physics_qa_dataset.json\")\n",
    "EVAL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not EVAL_PATH.exists():\n",
    "    demo_eval = {\n",
    "        \"physics_qa_dataset\": [\n",
    "            {\"question\":\"What is the period of a simple pendulum of length 2 m on Earth?\", \"answer\":\"2.84 s\"},\n",
    "            {\"question\":\"State Newton's second law.\", \"answer\":\"F = m a\"},\n",
    "            {\"question\":\"What are the dimensions of Planck's constant?\", \"answer\":\"[M L^2 T^-1]\"},\n",
    "            {\"question\":\"Compute kinetic energy for m=5 kg, v=10 m/s.\", \"answer\":\"250 J\"},\n",
    "            {\"question\":\"What is the relation between photon energy and frequency?\", \"answer\":\"E = h f\"}\n",
    "        ]\n",
    "    }\n",
    "    with open(EVAL_PATH, \"w\") as f:\n",
    "        json.dump(demo_eval, f, indent=2)\n",
    "    print(\"Demo eval set created at\", EVAL_PATH)\n",
    "else:\n",
    "    print(\"Using existing eval set:\", EVAL_PATH)\n",
    "\n",
    "with open(EVAL_PATH, \"r\") as f:\n",
    "    eval_data = json.load(f)[\"physics_qa_dataset\"]\n",
    "\n",
    "print(f\"Loaded {len(eval_data)} evaluation questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Evaluate RAG accuracy on a small sample (N questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag(model: RAGPhysicsModel, questions: List[Dict[str,str]], n: int = 5):\n",
    "    rows, correct = [], 0\n",
    "    N = min(n, len(questions))\n",
    "    for q in questions[:N]:\n",
    "        out = model.answer(q[\"question\"])\n",
    "        got = out[\"answer\"]\n",
    "        exp = q[\"answer\"]\n",
    "        is_correct = exp.lower() in got.lower()\n",
    "        rows.append({\n",
    "            \"question\": q[\"question\"],\n",
    "            \"expected\": exp,\n",
    "            \"got\": got,\n",
    "            \"sources\": out.get(\"sources\", []),\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "    acc = correct / max(1, N)\n",
    "    return pd.DataFrame(rows), acc\n",
    "\n",
    "df_rag, rag_acc = evaluate_rag(rag_model, eval_data, n=5)\n",
    "print(df_rag.to_string(index=False))\n",
    "print(f\"\\nRAG Accuracy (small sample): {rag_acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Plot accuracy (optionally compare vs baseline if you have it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a real baseline accuracy number, set it here; otherwise only plot RAG.\n",
    "BASELINE_ACC = None  # e.g., 0.423 if available\n",
    "\n",
    "labels, values = [\"RAG\"], [rag_acc]\n",
    "if isinstance(BASELINE_ACC, (int, float)):\n",
    "    labels = [\"Baseline\", \"RAG\"]\n",
    "    values = [BASELINE_ACC, rag_acc]\n",
    "\n",
    "plt.bar(labels, values)\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Accuracy (small sample)\")\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.02, f\"{v*100:.1f}%\", ha='center')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
